#### 외부 파일 입출력 함수
##### *pd.read_csv
```py
pd.read_csv(file,         # 파일명
            sep=',',      # 분리구분기호
            header=,      # 첫번째 행을 컬럼화할지 여부,None 설정시 value로 전달
            names=,       # 컬럼이름 변경
            index_col=,   # index설정 컬럼
            usecols=,     # 불러올 컬럼 전달
            dtype=,       # 불러올 데이터 타입 전달,딕셔너리로 각 컬럼별 전달가능
            engine=,      # 'python'주로 사용
            skiprows=,    # 제외할 행 전달
            nrows=,       # 불러올 행 개수 전달
            na_values=,   # NA처리할 문자열
            parse_dates=, # 날짜 파싱할 컬럼 전달
            encoding=)    # 인코딩 옵션

pd.read_csv('read_test.csv',parse_dates=['date']).dtypes #날짜로파싱,datetime64
#파싱: 날짜를 인식시키는 개념?
pd.read_csv('read_test.csv',header=None) # 컬럼이름이 값으로 들어감
pd.read_csv('read_test.csv',header=None,names=['A','B','C','D','E'])
pd.read_csv('read_test.csv',index_col='date') #date가 value에서는 제거됨
pd.read_csv('read_test.csv',usecols=['date']) # date 컬럼 불러오기
pd.read_csv('read_test.csv',dtype={'a':'str','c':'float'}).dtypes
pd.read_csv('read_test.csv',na_values=['.','-','?','!']) # na로 바꿈
# na처리는 딕셔너리로 각 컬럼별 전달 가능!!

pd.read_csv('read_test.csv',nrows=5)    # 컬럼 이름도 포함
pd.read_csv('read_test.csv',skiprows=5) # 컬럼 이름도 포함, 행개수
pd.read_csv('read_test.csv',skiprows=[1,5]) #행 넘버
```
--------
---------
#### [적용함수 - map함수, 메서드 map, apply, applymap]
```py
# 1. map함수
#-1차원 데이터 셋(list,array,series) 적용 가능
#-리스트로 출력 필요
#-map(fuc,*iterables): 함수가 필요로 하는 추가 인자 전달 가능

# 2. map메서드
#- 1차원 데이터 셋(Series, index object) 적용 가능
#-df1.col1.map(arg,na_action=None): 함수가 필요로 하는 추가 인자 전달 불가

# 3. apply 메서드
#-2차원 데이터 셋(DataFrame) 적용 가능
#- 적용함수에 Series형태(그룹)로 데이터를 전달, 그룹함수와 잘 어울림
#- df1.apply(func,axis=0,**kwds): 함수가 필요로 하는 추가인자 전달 가능

# 4. applymap 메서드
#- 2차원 데이터 셋(DataFrame) 적용 가능, 원소별 연산 수행
#- df1.applymap(func): 함수가 필요로 하는 추가 인자 전달 불가


# 예제) 다음의 데이터프레임에서 col1 컬럼 천단위 구분기호 제거
df1=DataFrame({'col1':['1,100','1,200','1,300'],
               'col2':['2,200','3,300','4,400']})
#  col1   col2
# 0  1,100  2,200
# 1  1,200  3,300
# 2  1,300  4,400

def f1(x):
    return(int(x.replace(',','')))
df1.applymap(f1)
#  col1  col2
# 0  1100  2200
# 1  1200  3300
# 2  1300  4400


# 예제) test3.txt를 불러온 뒤 년도별 총 합 구하기 17:00 set_index
np.loadtxt('test3.txt')   #공백, 탭 자동 분리
pd.read_csv('test3.txt',sep='\t')  # 분리구분기호 탭 전달
pd.read_csv('test3.txt',sep='\s+') # 하나의 공백이상 모두 구분 space +의미

df1=pd.read_csv('test3.txt',sep='\t',header=None)
f1 = lambda x : str(x) + '년'
df1.index = list(map(f1, np.arange(2000,2014)))
df1.apply(sum,axis=1)
df1.columns=['1월','2월','3월','4월','5월']
```
----------------
---------------
#### [연습문제 - read_csv, 적용함수]
```py
# [연습 문제]
# top(data,n=5) 함수 생성, 위 데이터에서 각 년도별 값이 큰 2개 월 출력
# 단, 사용자가 n의 값을 전달할 수 있도록
#        0    1
#2000년  1월  2월
#2001년  1월  2월
def top(data,n=5):
    df=DataFrame([])
    for i in range(0,14):
        df=df.append(Series(data.sort_values(data.index[i],
                                             axis=1).columns[0:n]),
                     ignore_index=True)
    return(df)    
top(df1,n=4)
###다른 풀이###
df1
def f1(x):
    return(x.index[0:2])
    
df1.apply(f1,axis=1)
df1.sort_values[0:n].columns

def top(data,n=5):
    def f1(x):
        return(x.sort_values.index[0:n])
    return(data.apply(f1,axis=1))

top(df1,n=5)

df1.iloc[1,:].sort_values.index
```

```py
# 1. subway2.csv  파일을 읽고(loadtxt로 불러온 후 데이터프레임 변경)
# 1) 다음의 데이터 프레임 형식으로 변경
# 전체     구분   5시       6시     7시 ...
# 서울역  승차 17465  18434  50313 ...
# 서울역  하차 ....
run profile1
df1 = pd.read_csv('subway2.csv', delimiter=',', dtype='str', skiprows=1, 
                   encoding='CP949')
#   전체  구분     05~06     06~07  ...      21~22      22~23     23~24     24~01
# 0    서울역(1)  승차   17,465    18,434   ...   116,350     88,902    49,049     4,558 
# 1       NaN  하차    7,829    48,553   ...    59,285     50,266    32,182    13,943 


# 만약 결측치가 NaN이 아니라 공백이었다면??
# 전체컬럼 수정
# sol1) 치환 대상만 추출 후 치환
df1.loc[:,'전체'][df1.loc[:,'전체'] == ''] = NA

# sol2) 조건에 따른 치환(전체범위 치환)
np.where(df1.loc[:,'전체'] == '', NA, df1.loc[:,'전체'])


# NaN 역으로 치환하기
df1.loc[:,'전체'] = df1.loc[:,'전체'].fillna(method='ffill')


# column 수정
c1 = df1.columns.values

f1 = lambda x : str(int(x[:2])) + '시'
c1[2:] = Series(c1[2:]).map(f1)

df1.columns = c1


# 2) 각 역별 하차의 총 합
# 승하차 인원(5시~24시 컬럼) 숫자 변경

#먼저 콤마 삭제하기
f_replace = lambda x : x.replace(',','')
df1.loc[:,'5시':] = df1.loc[:,'5시':].applymap(f_replace)

# sol1) 벡터연산 가능한 astype 메서드 사용
df1.loc[:,'5시':] = df1.loc[:,'5시':].astype('int')

# sol2) int + applymap을 통한 전체 치환
f2 = lambda x : int(x)
df1.loc[:,'5시':].applymap(f2)

# 하차 추출
df2 = df1.loc[df1.loc[:,'구분'] == '하차', :]
df2 = df2.set_index('전체') #'전체' 컬럼을 index로 변경
df2 = df2.drop('구분',axis=1) # 구분 컬럼 없애기, 이때 axis는 기존과 반대
df2 = df2.astype('int')

df2.sum(axis=1)
# 전체
# 서울역(1)    1565575
# 시 청(1)     835631
# 종 각       1516661
df2.apply(sum, axis=1) # 위와 같은 결과

############[ 참고 - set_index 메서드 ]##############
# 본문에서 특정 컬럼을 index로 전달하고자 할때 전달과 동시에 본문에서 해당 컬럼 제외
# 단, 인덱스 설정만 가능하고 컬럼 설정은 불가
df1.set_index('전체')          # '전체' 컬럼을 인덱스로 처리, 본문에서 제외
df1.set_index(['전체','구분'])  # '전체','구분' 컬럼을 멀티 인덱스로 처리
#               5시     6시      7시      8시  ...     21시     22시    23시    24시
# 전체     구분                                ...                              
# 서울역(1) 승차  17465  18434   50313   93398  ...  116350   88902  49049   4558
#        하차   7829  48553  110250  233852  ...   59285   50266  32182  13943
df1.reset_index()              # 이미 설정된 인덱스를 다시 컬럼으로 꺼내기


# 3) 승차의 시간대별 총 합
df3 = df1.loc[df1.loc[:,'구분'] == '승차', :]
df3 = df3.set_index('전체') 
df3 = df3.drop('구분',axis=1)
df3 = df3.astype('int')

df3.sum(axis=0)
df3.apply(sum,axis=0)
# 5시     1091077
# 6시     2093867
# 7시     5707011


# 4) top(data,n=5) 함수 생성, 각 역별 승차가 많은 top 5 시간대 출력
df3.loc['서울역(1)',:].sort_values(ascending=False)[:5]

def top(data,n=5) :
    return data.sort_values(ascending=False)[:5]

top(df3.loc['서울역(1)',:])

 
# 5) 하차 인원의 시간대별 각 역의 차지 비율 출력
df2.loc[:,'5시'] / df2.loc[:,'5시'].sum() * 100
df2.loc[:,'6시'] / df2.loc[:,'6시'].sum() * 100
...

f3 = lambda x : x / x.sum() * 100
df2.apply(f3,axis=0)

# [ 참고-fillna 메서드 ]
s1 = Series([1,NA,2,NA,2])
s1.fillna(method='ffill')   # 이전값으로 치환
s1.fillna(method='bfill')   # 이후값으로 치환
```